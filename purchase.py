import streamlit as st
import json
from io import BytesIO
from PIL import Image
import google.generativeai as genai
from google.api_core import exceptions
import time
import os
import re
from typing import Any, Dict, List, Optional
import pandas as pd

# ==========================================
# ğŸ§¾ Invoice Extractor â€“ Gemini 1.5 (dotenv, RTL, Editable + Vendor Memory)
# - Uses ONLY dotenv env var GEMINI_API_KEY (no st.secrets)
# - Arabic schema keys (compatible with your current data model)
# - User can EDIT extracted lines; saves corrections to vendor_corrections.jsonl
# - "Vendor Memory": re-run with few-shot guidance learned from past corrections
# - Auto-detect/sanitize numbers; prevent size tokens as codes; basic swap-fix via memory
# ==========================================

st.set_page_config(layout="wide", page_title="ğŸ§¾ Invoice Extractor â€“ Vendor Memory")



# ---------- helpers ----------
ARABIC_INDIC = str.maketrans("Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©Ù«Ù¬", "0123456789..")
CAPACITY_TOKENS = re.compile(r"(?i)\b(?:ml|ltrs?|ltr|gms?|gm|grams?|Ø¬Ù…|Øº|Ù…Ù„|Ù„ØªØ±|ÙƒØ¬Ù…|kg|ÙƒÙŠÙ„Ùˆ)\b")
MEMORY_PATH = "vendor_corrections.jsonl"


model_name = "gemini-2.0-flash"
def normalize_number(val: Any) -> Optional[float]:
    if val is None:
        return None
    if isinstance(val, (int, float)):
        return float(val)
    s = str(val).strip().translate(ARABIC_INDIC)
    s = s.replace("\u00A0", " ")
    s = re.sub(r"[\s\$Â£â‚¬Â¥Ø±.Ø³Ø¬.Ø¯]*", "", s)
    s = s.replace(",", "")
    s = re.sub(r"\.(?=.*\.)", "", s)
    try:
        return float(s)
    except Exception:
        return None


def coerce_nulls(x: Any) -> Any:
    if isinstance(x, dict):
        return {k: coerce_nulls(v) for k, v in x.items()}
    if isinstance(x, list):
        return [coerce_nulls(v) for v in x]
    if isinstance(x, str) and x.strip() == "":
        return None
    return x


def normalize_item_code(code: Optional[str]) -> Optional[str]:
    if not code:
        return code
    s = re.sub(r"\s+", " ", str(code)).strip()
    s = re.sub(r"^-+", "", s)
    s = " ".join(p for p in s.split() if not CAPACITY_TOKENS.search(p)).strip()
    if re.fullmatch(r"[A-Za-z0-9][A-Za-z0-9\- ]*", s):
        return s or None
    return s or None


def as_float_if_numeric_str(val: Any) -> Optional[float]:
    if val is None:
        return None
    if isinstance(val, (int, float)):
        return float(val)
    s = str(val).strip()
    if re.fullmatch(r"\d+(?:\.\d+)?", s):
        try:
            return float(s)
        except Exception:
            return None
    return None

def fill_after_tax_if_missing(item: dict, vat_rate: Optional[float] = None) -> None:
    # reserved for future use if you want to auto-compute TOTAL_AFTR_TAX using a global VAT
    if vat_rate is None:
        return
    if item.get("TOTAL_AFTR_TAX") is None and isinstance(item.get("TOTAL_BFR_TAX"), (int, float)):
        before = float(item["TOTAL_BFR_TAX"])
        item["TOTAL_AFTR_TAX"] = round(before * (1.0 + vat_rate), 2)

def validate_and_fix_schema(data: dict) -> dict:
    """
    Normalize whatever the model returns (Arabic keys or partial) into the target schema:
    VNDR_NM, CSTMR_NM, DOC_NO, DOC_NO_TAX, ITEMS[ ITM_* ].
    Also apply an arithmetic swap-fix for ITM_CODE â†” ITM_QTY when needed.
    """
    # Top-level mapping (accept Arabic or English keys)
    vndr = data.get("VNDR_NM") or data.get("Ø§Ø³Ù…_Ø§Ù„Ù…ÙˆØ±Ø¯")
    cstm = data.get("CSTMR_NM") or data.get("Ø§Ø³Ù…_Ø§Ù„Ø¹Ù…ÙŠÙ„")
    doc  = data.get("DOC_NO") or data.get("Ø±Ù‚Ù…_Ø§Ù„ÙØ§ØªÙˆØ±Ø©")
    doct = data.get("DOC_NO_TAX") or data.get("Ø±Ù‚Ù…_Ø§Ù„ÙØ§ØªÙˆØ±Ø©_Ø§Ù„Ø¶Ø±ÙŠØ¨ÙŠØ©")
    items = data.get("ITEMS") or data.get("Ø§Ù„Ø£ØµÙ†Ø§Ù")

    if not isinstance(items, list):
        items = [] if items is None else [items]

    fixed_items: List[Dict[str, Any]] = []
    for item in items:
        item = item or {}
        code         = item.get("ITM_CODE")           or item.get("Ø±Ù‚Ù…_Ø§Ù„ØµÙ†Ù")
        name_ar      = item.get("ITM_L_NM")           or item.get("Ø§Ø³Ù…_Ø§Ù„ØµÙ†Ù")
        name_en      = item.get("ITM_F_NM")           or item.get("Ø§Ø³Ù…_Ø§Ù„ØµÙ†Ù_Ø§Ù†Ø¬Ù„ÙŠØ²ÙŠ")
        unit         = item.get("ITM_UNT")            or item.get("Ø§Ù„ÙˆØ­Ø¯Ø©")
        qty          = item.get("ITM_QTY")            or item.get("Ø§Ù„ÙƒÙ…ÙŠØ©")
        price        = item.get("ITM_PRICE")          or item.get("Ø³Ø¹Ø±_Ø§Ù„ÙˆØ­Ø¯Ø©")
        total_before = item.get("TOTAL_BFR_TAX")      or item.get("Ø§Ù„Ø§Ø¬Ù…Ø§Ù„ÙŠ_Ù‚Ø¨Ù„_Ø§Ù„Ø¶Ø±ÙŠØ¨Ø©")
        disc         = item.get("ITM_DSCNT")          or item.get("Ø§Ù„Ø®ØµÙ…")
        total_after  = item.get("TOTAL_AFTR_TAX")     or item.get("Ø§Ù„Ø§Ø¬Ù…Ø§Ù„ÙŠ_Ø¨Ø¹Ø¯_Ø§Ù„Ø¶Ø±ÙŠØ¨Ø©")

        fixed = {
            "ITM_CODE":        normalize_item_code(code),
            "ITM_L_NM":        name_ar,
            "ITM_F_NM":        name_en,
            "ITM_UNT":         unit,
            "ITM_QTY":         normalize_number(qty),
            "ITM_PRICE":       normalize_number(price),
            "TOTAL_BFR_TAX":   normalize_number(total_before),
            "ITM_DSCNT":       normalize_number(disc) or 0.0,
            "TOTAL_AFTR_TAX":  normalize_number(total_after),
        }

        # Arithmetic swap-fix (detect if QTY and CODE were swapped)
        qty_v      = fixed["ITM_QTY"]
        code_str   = fixed["ITM_CODE"]
        code_num   = as_float_if_numeric_str(code_str)
        unit_price = fixed["ITM_PRICE"]
        line_total = fixed["TOTAL_BFR_TAX"]

        if unit_price and line_total and unit_price != 0:
            expected_qty = line_total / unit_price
            eps = max(0.02, abs(expected_qty) * 0.01)  # Â±1% or 0.02
            def close(a, b): return (a is not None and b is not None and abs(a - b) <= eps)
            qty_matches  = close(qty_v, expected_qty)
            code_matches = close(code_num, expected_qty)

            if (not qty_matches) and code_matches:
                prev_qty = qty_v
                fixed["ITM_QTY"] = code_num
                if isinstance(prev_qty, (int, float)) and abs(prev_qty - round(prev_qty)) < 1e-6 and 0 < prev_qty <= 1_000_000:
                    fixed["ITM_CODE"] = str(int(round(prev_qty)))
                else:
                    fixed["ITM_CODE"] = code_str if code_str and not re.fullmatch(r"\d+(?:\.\d+)?", code_str) else None

        # (optional) fill_after_tax_if_missing(fixed, vat_rate=None)
        fixed_items.append(fixed)

    out = {
        "VNDR_NM":   vndr,
        "CSTMR_NM":  cstm,
        "DOC_NO":    doc,
        "DOC_NO_TAX": doct,
        "ITEMS":     fixed_items,
    }
    return coerce_nulls(out)



# ---------- lightweight vendor memory ----------

def load_memory() -> List[dict]:
    if not os.path.exists(MEMORY_PATH):
        return []
    try:
        with open(MEMORY_PATH, "r", encoding="utf-8") as f:
            return [json.loads(line) for line in f if line.strip()]
    except Exception:
        return []


def save_memory(record: dict) -> None:
    try:
        with open(MEMORY_PATH, "a", encoding="utf-8") as f:
            f.write(json.dumps(record, ensure_ascii=False) + "\n")
    except Exception:
        pass


def get_vendor_examples(vendor: str, max_n: int = 3) -> List[dict]:
    mem = load_memory()
    examples = [r for r in mem if (r.get("Ø§Ø³Ù…_Ø§Ù„Ù…ÙˆØ±Ø¯") == vendor or r.get("VNDR_NM") == vendor)]
    return examples[:max_n]


def build_vendor_hint(vendor: str) -> str:
    ex = get_vendor_examples(vendor)
    if not ex:
        return ""
    lines = ["\n\nğŸ“Œ Vendor-specific guidance (learned from previous corrections):", f"- Vendor: {vendor}"]
    for i, r in enumerate(ex, start=1):
        items = r.get("Ø§Ù„Ø£ØµÙ†Ø§Ù") or r.get("ITEMS") or []
        if not items:
            continue
        s = items[0]
        code = s.get("Ø±Ù‚Ù…_Ø§Ù„ØµÙ†Ù") or s.get("ITM_CODE")
        qty = s.get("Ø§Ù„ÙƒÙ…ÙŠØ©") or s.get("ITM_QTY")
        lines.append(f"  â€¢ Example {i}: item_code='{code}', qty={qty}  â†’ code from rightmost code column; qty from QTY column")
    lines.append("- Never use size tokens (e.g., 230ML, 160 Gms) as codes. If unit_price*qty mismatches but unit_price*code matches the line total, swap them.")
    return "\n".join(lines)


# ---------- Gemini ----------

def get_api_key() -> Optional[str]:
    try:
        return st.secrets["GEMINI_API_KEY"]
    except Exception:
        return None


@st.cache_resource(show_spinner=False)
def get_model(model_name: str = model_name, enforce_json: bool = True):
    api_key = get_api_key()
    if not api_key:
        raise RuntimeError("GEMINI_API_KEY is not set in environment (.env)")
    genai.configure(api_key=api_key)
    generation_config = {"response_mime_type": "application/json"} if enforce_json else {}
    return genai.GenerativeModel(model_name=model_name, generation_config=generation_config)


def image_to_jpeg_bytes(img: Image.Image, max_side: int = 2400, quality: int = 92) -> bytes:
    try:
        img = img.convert("RGB")
    except Exception:
        img = img.convert("RGB")
    w, h = img.size
    scale = min(1.0, max_side / max(w, h))
    if scale < 1.0:
        img = img.resize((int(w * scale), int(h * scale)))
    buf = BytesIO()
    img.save(buf, format="JPEG", optimize=True, quality=quality)
    return buf.getvalue()


def call_gemini_api(image_bytes: bytes, prompt: str, model_name: str) -> tuple[Optional[dict], Optional[str]]:
    if not image_bytes:
        return None, "Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙˆØ±Ø©"
    try:
        model = get_model(model_name, enforce_json=True)
    except Exception as e:
        return None, f"ØªÙ‡ÙŠØ¦Ø© ÙØ´Ù„Øª: {e}"

    last_err = None
    delay = 2
    for attempt in range(5):
        try:
            img = Image.open(BytesIO(image_bytes)).convert("RGB")
            resp = model.generate_content([prompt, img])
            text = getattr(resp, "text", "") or ""
            try:
                data = json.loads(text)
            except Exception:
                # try to recover first {...}
                data = None
                stack, start = [], None
                for i, ch in enumerate(text):
                    if ch == '{':
                        if not stack:
                            start = i
                        stack.append(ch)
                    elif ch == '}':
                        if stack:
                            stack.pop()
                            if not stack and start is not None:
                                cand = text[start:i+1]
                                try:
                                    data = json.loads(cand)
                                    break
                                except Exception:
                                    start = None
                                    continue
            if not data:
                raise ValueError("JSON ØºÙŠØ± ØµØ§Ù„Ø­")
            return data, None
        except exceptions.ResourceExhausted as e:
            last_err = str(e)
            if attempt < 4:
                time.sleep(delay)
                delay *= 2
            else:
                return None, "ØªØ¬Ø§ÙˆØ² Ø­Ø¯ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙƒØ«ÙŠØ±Ù‹Ø§"
        except Exception as e:
            last_err = str(e)
            if attempt < 4:
                time.sleep(delay)
                delay *= 2
            else:
                return None, f"Ø®Ø·Ø£: {e}"
    return None, last_err or "ÙØ´Ù„ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"


USER_PROMPT = r"""
**CRITICAL TASK: Parse the invoice image and return ONLY a valid JSON (UTF-8) matching EXACTLY this schema and keys.**

Top-level keys:
- "VNDR_NM": string|null  (Vendor name)
- "CSTMR_NM": string|null (Customer name)
- "DOC_NO": string|null   (Invoice number)
- "DOC_NO_TAX": string|null (Tax invoice number; if not printed, return null)
- "ITEMS": [ { line objects as below } ]

For each line in ITEMS (read the item table rows):
- "ITM_CODE": string|null  â†’ Value from the Item Code column ONLY (Arabic RTL invoices often put this on the FAR RIGHT). It may be a simple integer like 6, 14, 28 OR a dashed code like 09-001-010. Never take numbers from the description or from QTY. If the code wraps across lines, join the parts while keeping dashes/spaces.
- "ITM_L_NM": string|null  â†’ Arabic description ONLY
- "ITM_F_NM": string|null  â†’ English description for the same row ONLY
- "ITM_UNT": string|null   â†’ Unit, only if there is a dedicated unit column; else null
- "ITM_QTY": number|null   â†’ Quantity from QTY/Ø§Ù„ÙƒÙ…ÙŠØ© column ONLY
- "ITM_PRICE": number|null â†’ Unit price
- "TOTAL_BFR_TAX": number|null â†’ Line total before VAT/tax
- "ITM_DSCNT": number      â†’ Discount amount for the line; 0 if none
- "TOTAL_AFTR_TAX": number|null â†’ Line total after VAT/tax; if not printed per-line, return null.

STRICT RULES:
1) Read Arabic invoices from RIGHT to LEFT. The Item Code column is often the rightmost column. Do NOT confuse it with the counter (#) or QTY.
2) Do NOT use size/capacity tokens from description as codes (e.g., 230ML, 160 Gms, 1 Ltrs, 230 Ø¬Ù…). Those are not item codes.
3) All numeric values must be JSON numbers (not strings). Keep decimal precision as printed.
4) If a field is not present, return null.
5) Self-check: if (ITM_PRICE Ã— ITM_QTY) does NOT approximately equal TOTAL_BFR_TAX (Â±1%), BUT (ITM_PRICE Ã— ITM_CODE_as_number_if_numeric) DOES â‰ˆ TOTAL_BFR_TAX, then you swapped QTY and CODE; fix it so that QTY holds the value satisfying the equation, and CODE holds the other value.

Return ONLY the JSON object, nothing else.
"""



# ---------- UI ----------
with st.sidebar:
    api_key = st.secrets.get("GEMINI_API_KEY", None)

    use_memory = st.checkbox("ğŸ§  Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…ÙˆØ±Ø¯ÙŠÙ† Ø¹Ù†Ø¯ Ø§Ù„Ø¥Ø¹Ø§Ø¯Ø©", value=True)

st.title("ğŸ§¾ Ù…Ø³ØªØ®Ø±Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙÙˆØ§ØªÙŠØ± â€“ Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ¹Ø¯ÙŠÙ„ Ù…Ø¹ Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…ÙˆØ±Ø¯ÙŠÙ†")
st.markdown("---")

# upload
try:
    from pdf2image import convert_from_bytes
    PDF_SUPPORT = True
except Exception:
    PDF_SUPPORT = False
    st.warning("Ù„Ù… ÙŠØªÙ… ØªØ«Ø¨ÙŠØª pdf2image â€“ Ù„Ù† ØªÙØ­ÙˆÙ‘Ù„ Ù…Ù„ÙØ§Øª PDF.")

files = st.file_uploader("Ø§Ø±ÙØ¹ ÙÙˆØ§ØªÙŠØ± (PDF/JPG/PNG)", type=["pdf","jpg","jpeg","png"], accept_multiple_files=True)

results: List[Dict[str, Any]] = []
previews: List[Dict[str, Any]] = []

if files:
    col1, col2 = st.columns([1, 1.3])

    with col1:
        st.subheader("Ø§Ù„Ù…Ø¹Ø§ÙŠÙ†Ø©")
        for f in files:
            if f.type == "application/pdf" and PDF_SUPPORT:
                pages = convert_from_bytes(f.getvalue(), dpi=200)
                for i, p in enumerate(pages, 1):
                    previews.append({"name": f"{f.name} â€“ {i}", "image": p})
                    st.image(p, caption=f"{f.name} â€“ {i}", use_column_width=True)
            else:
                img = Image.open(f)
                previews.append({"name": f.name, "image": img})
                st.image(img, caption=f.name, use_column_width=True)

    with col2:
        st.subheader("Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬")
        if st.button("ğŸš€ Ø§Ø³ØªØ®Ø±Ø§Ø¬", type="primary", disabled=not api_key):
            total = len(previews)
            prog = st.progress(0, text=f"ØªØ­Ù„ÙŠÙ„ {total} ØµÙØ­Ø©â€¦")
            for i, item in enumerate(previews, 1):
                prog.progress(i/total, text=f"{i}/{total}")
                img_bytes = image_to_jpeg_bytes(item["image"], max_side=2400)

                # Ø®Ø·ÙˆØ© 1: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø³Ø§Ø³ÙŠ
                raw1, err1 = call_gemini_api(img_bytes, USER_PROMPT, model_name)
                with st.expander(f"ğŸ“„ {item['name']}", expanded=True):
                    if not raw1:
                        st.error(err1)
                        continue
                    fixed1 = validate_and_fix_schema(raw1)

                    # Ù…Ø­Ø±Ø± Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ¹Ø¯ÙŠÙ„
                    vendor = fixed1.get("Ø§Ø³Ù…_Ø§Ù„Ù…ÙˆØ±Ø¯") or ""
                    st.markdown(f"**Ø§Ù„Ù…ÙˆØ±Ø¯:** {vendor}")
                    df = pd.DataFrame(fixed1.get("Ø§Ù„Ø£ØµÙ†Ø§Ù", []))
                    edited_df = st.data_editor(df, use_container_width=True, num_rows="dynamic", key=f"edit_{i}")

                    colA, colB, colC = st.columns(3)
                    with colA:
                        if st.button("ğŸ’¾ Ø­ÙØ¸ Ø§Ù„ØªØµØ­ÙŠØ­Ø§Øª ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©", key=f"save_{i}"):
                            fixed1["Ø§Ù„Ø£ØµÙ†Ø§Ù"] = edited_df.fillna(value=None).to_dict(orient="records")
                            save_memory({"Ø§Ø³Ù…_Ø§Ù„Ù…ÙˆØ±Ø¯": vendor, **fixed1})
                            st.success("ØªÙ… Ø§Ù„Ø­ÙØ¸. Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‡Ø°Ù‡ Ø§Ù„ØªØµØ­ÙŠØ­Ø§Øª ÙƒØ£Ù…Ø«Ù„Ø© Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©.")
                    with colB:
                        st.download_button("â¬‡ï¸ ØªÙ†Ø²ÙŠÙ„ JSON", data=json.dumps(fixed1, ensure_ascii=False).encode("utf-8"), file_name=f"{item['name']}.json", mime="application/json", key=f"dl_{i}")
                    with colC:
                        if use_memory and vendor and st.button("ğŸ” Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…ÙˆØ±Ø¯", key=f"rerun_{i}"):
                            hint = build_vendor_hint(vendor)
                            prompt2 = USER_PROMPT + ("\n" + hint if hint else "")
                            raw2, err2 = call_gemini_api(img_bytes, prompt2, model_name)
                            if raw2:
                                fixed2 = validate_and_fix_schema(raw2)
                                st.markdown("**Ù†ØªÙŠØ¬Ø© Ø¨Ø¹Ø¯ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©:**")
                                st.json(fixed2)
                                # Ø§Ù‚ØªØ±Ø§Ø­: ÙŠÙ…ÙƒÙ† Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ÙØ±ÙˆÙ‚Ø§Øª Ù‡Ù†Ø§ Ø¥Ø°Ø§ Ø±ØºØ¨Øª
                            else:
                                st.warning(f"ÙØ´Ù„ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬: {err2}")

                    st.markdown("**Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©:**")
                    st.json(fixed1)
                    results.append({"file": item["name"], "data": fixed1})

            prog.empty()
            st.success("Ø§ÙƒØªÙ…Ù„ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬")

        # Ø¹Ø±Ø¶ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ø§Ø®ØªÙŠØ§Ø±ÙŠÙ‹Ø§
        with st.expander("ğŸ§  Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…ÙˆØ±Ø¯ÙŠÙ† Ø§Ù„Ù…Ø®Ø²Ù†Ø©"):
            mem = load_memory()
            st.write(f"{len(mem)} Ø³Ø¬Ù„/Ø³Ø¬Ù„Ø§Øª Ù…ØµØ­Ø­Ø© Ù…Ø­ÙÙˆØ¸Ø©")
            if mem:
                st.dataframe(pd.DataFrame([{
                    "Ø§Ù„Ù…ÙˆØ±Ø¯": r.get("Ø§Ø³Ù…_Ø§Ù„Ù…ÙˆØ±Ø¯") or r.get("VNDR_NM"),
                    "Ø±Ù‚Ù… Ø§Ù„ÙØ§ØªÙˆØ±Ø©": r.get("Ø±Ù‚Ù…_Ø§Ù„ÙØ§ØªÙˆØ±Ø©") or r.get("DOC_NO"),
                    "Ø¹Ø¯Ø¯ Ø§Ù„Ø£ØµÙ†Ø§Ù": len(r.get("Ø§Ù„Ø£ØµÙ†Ø§Ù") or r.get("ITEMS") or [])
                } for r in mem]), use_container_width=True)

# ===== end of file =====
